# -*- coding: utf-8 -*-
"""Social_Media_Analytics_Twitter (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gwEZ4XqmkywFFdjha6MH1ez5ujO1zHh2
"""

# Mount Google Drive for data storage
from google.colab import drive # Import the necessary module for Google Drive integration
drive.mount('/content/drive')

import pandas as pd
from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification
import tensorflow as tf
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# --- 1. Data Loading and Exploration ---
data_path_train = '/content/drive/MyDrive/Twitter_Data/twitter_training.csv'  # Training data file name
data_path_test = '/content/drive/MyDrive/Twitter_Data/twitter_validation.csv'    # Validation/Testing data file name

try:
    # Load training data
    df_train = pd.read_csv(data_path_train, encoding='latin-1', header=None, names=['Tweet_ID', 'Entity', 'Sentiment', 'Tweet'])
    # Load validation/testing data
    df_test = pd.read_csv(data_path_test, encoding='latin-1', header=None, names=['Tweet_ID', 'Entity', 'Sentiment', 'Tweet'])
except FileNotFoundError:
    print("Error: One or both of the CSV files not found. Please check the file paths.")
    exit()

print("Training Data Shape:", df_train.shape)
print("Testing Data Shape:", df_test.shape)
print("\nTraining Data Sentiment Distribution:")
print(df_train['Sentiment'].value_counts())
print("\nTesting Data Sentiment Distribution:")
print(df_test['Sentiment'].value_counts())

# Filter out 'Irrelevant' sentiment and drop NaN tweets
df_train = df_train[df_train['Sentiment'] != 'Irrelevant'].dropna(subset=['Tweet', 'Sentiment']).reset_index(drop=True)
df_test = df_test[df_test['Sentiment'] != 'Irrelevant'].dropna(subset=['Tweet', 'Sentiment']).reset_index(drop=True)

print("\nTraining Data Shape (after filtering Irrelevant):", df_train.shape)
print("Testing Data Shape (after filtering Irrelevant):", df_test.shape)
print("\nTraining Data Sentiment Distribution (after filtering Irrelevant):")
print(df_train['Sentiment'].value_counts())
print("\nTesting Data Sentiment Distribution (after filtering Irrelevant):")
print(df_test['Sentiment'].value_counts())

# Convert sentiment labels to numerical values
sentiment_mapping = {'Positive': 2, 'Neutral': 1, 'Negative': 0} # Note the capitalization
df_train['Sentiment_Label'] = df_train['Sentiment'].map(sentiment_mapping)
df_test['Sentiment_Label'] = df_test['Sentiment'].map(sentiment_mapping)

# Drop rows where mapping failed (shouldn't happen after filtering)
df_train.dropna(subset=['Sentiment_Label'], inplace=True)
df_test.dropna(subset=['Sentiment_Label'], inplace=True)

# --- 2. Text Preprocessing ---
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.IGNORECASE)
    text = re.sub(r'@\S+', '', text)
    text = re.sub(r'#\S+', '', text)
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    text = text.lower()
    text = ' '.join([word for word in text.split() if word not in stop_words])
    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])
    return text

df_train['Cleaned_Tweet'] = df_train['Tweet'].apply(preprocess_text)
df_test['Cleaned_Tweet'] = df_test['Tweet'].apply(preprocess_text)

from transformers import DistilBertTokenizerFast

model_name = 'distilbert-base-uncased'
tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)

# Sample a portion of your cleaned training tweets
sample_tweets = df_train['Cleaned_Tweet'].sample(n=1000, random_state=42).tolist()

token_lengths = [len(tokenizer.encode(tweet, add_special_tokens=True)) for tweet in sample_tweets]

import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(token_lengths, bins=30, kde=True)
plt.title('Distribution of Tokenized Tweet Lengths')
plt.xlabel('Token Length')
plt.ylabel('Frequency')
plt.show()

print(f"Average token length: {sum(token_lengths) / len(token_lengths):.2f}")
print(f"Maximum token length: {max(token_lengths)}")
print(f"Length at 95th percentile: {np.percentile(token_lengths, 95)}")

# --- 3. BERT Model Loading and Tokenization (Using DistilBERT) ---
model_name = 'distilbert-base-uncased'
tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)
num_labels = len(sentiment_mapping)
model = TFDistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)

MAX_LEN = 64
print(f"Using MAX_LEN: {MAX_LEN}")

def tokenize_tweets(text):
    return tokenizer(text, max_length=MAX_LEN, padding='max_length', truncation=True, return_tensors='tf')

train_tokenized_data = df_train['Cleaned_Tweet'].apply(tokenize_tweets)
test_tokenized_data = df_test['Cleaned_Tweet'].apply(tokenize_tweets)

# --- 4. Dataset Preparation ---
def prepare_tf_dataset(tokenized_data, labels, batch_size=32):
    input_ids = []
    attention_masks = []
    for data in tokenized_data:
        input_ids.append(data['input_ids'][0])
        attention_masks.append(data['attention_mask'][0])
    input_ids = tf.convert_to_tensor(input_ids)
    attention_masks = tf.convert_to_tensor(attention_masks)
    # Explicitly cast labels to tf.int32
    labels = tf.cast(tf.convert_to_tensor(labels), tf.int32)
    dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': input_ids, 'attention_mask': attention_masks}, labels))
    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)
    return dataset

batch_size = 32
train_dataset = prepare_tf_dataset(train_tokenized_data, df_train['Sentiment_Label'].tolist(), batch_size)
val_dataset = prepare_tf_dataset(test_tokenized_data, df_test['Sentiment_Label'].tolist(), batch_size)

print("Train Dataset Element Spec:", train_dataset.element_spec)
print("Validation Dataset Element Spec:", val_dataset.element_spec)

# --- 5. Model Training/Fine-tuning (Custom Training Loop for Debugging) ---
optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

@tf.function
def train_step(inputs, labels):
    with tf.GradientTape() as tape:
        predictions = model(inputs).logits
        # Explicitly reshape labels to (batch_size, 1)
        reshaped_labels = tf.expand_dims(labels, axis=-1)
        loss = loss_fn(reshaped_labels, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss

epochs = 3

for epoch in range(epochs):
    print(f"Epoch {epoch + 1}")
    for step, (inputs, labels) in enumerate(train_dataset):
        loss = train_step(inputs, labels)
        if step % 100 == 0:
            print(f"  Step {step}, Loss: {loss:.4f}")

print("\nUnique actual sentiments in the validation set:", np.unique(actual_sentiments))
print("Sentiment mapping:", sentiment_mapping)
print("Reverse sentiment mapping:", reverse_sentiment_mapping)
print("\nClassification Report:")
print(classification_report(actual_sentiments, predicted_sentiments, labels=list(reverse_sentiment_mapping.values())))

# --- 6. Model Evaluation (Custom Evaluation Loop with Metrics) ---
epoch_val_loss = tf.keras.metrics.Mean()
epoch_val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()
epoch_val_precision = tf.keras.metrics.Precision()
epoch_val_recall = tf.keras.metrics.Recall()

for inputs, labels in val_dataset:
    predictions = model(inputs).logits
    reshaped_labels = tf.expand_dims(labels, axis=-1)
    loss = loss_fn(reshaped_labels, predictions)
    epoch_val_loss.update_state(loss)
    epoch_val_accuracy.update_state(labels, predictions)
    epoch_val_precision.update_state(labels, tf.argmax(predictions, axis=1))
    epoch_val_recall.update_state(labels, tf.argmax(predictions, axis=1))

loss = epoch_val_loss.result().numpy()
accuracy = epoch_val_accuracy.result().numpy()
precision = epoch_val_precision.result().numpy()
recall = epoch_val_recall.result().numpy()

print(f"\nTest Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall: {recall:.4f}")

predictions = model.predict(val_dataset)
predicted_labels = tf.argmax(predictions.logits, axis=1).numpy()
all_val_labels = tf.concat([y for x, y in val_dataset], axis=0).numpy()
reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}
predicted_sentiments = [reverse_sentiment_mapping[label] for label in predicted_labels]
actual_sentiments = [reverse_sentiment_mapping[label] for label in all_val_labels]

import numpy as np
print("\nUnique actual sentiments in the validation set:", np.unique(actual_sentiments))
print("Sentiment mapping:", sentiment_mapping)
print("Reverse sentiment mapping:", reverse_sentiment_mapping)

present_labels = np.unique(actual_sentiments).tolist()
print("\nClassification Report:")
print(classification_report(actual_sentiments, predicted_sentiments, labels=present_labels))

cm = confusion_matrix(actual_sentiments, predicted_sentiments, labels=list(reverse_sentiment_mapping.values()))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=reverse_sentiment_mapping.values(),
            yticklabels=reverse_sentiment_mapping.values())
plt.title('Confusion Matrix')
plt.xlabel('Predicted Sentiment')
plt.ylabel('Actual Sentiment')
plt.show()